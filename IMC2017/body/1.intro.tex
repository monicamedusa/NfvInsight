\section{Introduction}
Emerging network function virtualization (NFV) was initiated to replace hardware middleboxes with software implementation running in virtual machines (VMs), which would highly lower capital costs of network infrastructure and bring greater openness and flexibility.
% With the help of virtualization, we could manage multiple virtual network functions directly by standards virtualization management tools, as Openstack and K8s. could be directly managed by virtualization management tools, as Openstack, K8s.
% Virtualization bring much advantages to network functions, as ease of deployment, live migration, and so forth.
It is really exciting to encapsulate network functions into VMs, multiplexing underlying commodity, general purpose processors rather than dedicated physical boxes.
Thus NFV rapidly gains significant attention by industry and academia. Plenty of works has devoted much effort to simplify building, deploying and managing NFs, like OpenNF \cite{gember-jacobson_opennf:_2014}, CoMb \cite{180672} and E2 \cite{palkar_e2:_2015}, or rewriting efficient NFs, like OpenBox \cite{bremler-barr_openbox:_2016} and Netbricks \cite{199352}.

% Network function virtualization (NFV) has become a hot topic, both in industry and academia.
% Since the publication of NFV Introductory White Paper \cite{} of ETSI in 2012, a lot of works have been emerged in this field.
% Modification works of NFV were done on the whole software stack (or maybe both SW and HW stack?).
% There are de facto industrial NFV platform OPNFV \cite{noauthor_home_nodate} as well as advanced NF allocation frameworks like OpenNF \cite{gember-jacobson_opennf:_2014}, CoMb \cite{180672} and E2 \cite{palkar_e2:_2015}.
% Also, there are works like OpenBox \cite{bremler-barr_openbox:_2016} and Netbricks \cite{199352} to rewrite or modify the NFs.

%Embark\cite{194934}
%StateAlyzer\cite{194932}
%Split/Merge\cite{180307}
%ClickOS\cite{179771}
%APLOMB\cite{sherry_making_2012}
%FTMB\cite{sherry_rollback-recovery_2015}
%DFC\cite{194970}

However, although virtualization saves much time of NFs management for us, building a NFV testbed still seems to be a time-consuming and annoying experience. Recently we surveyed experienced researchers on networking who claimed ever build a NFV testbed. Surprisingly, we find that it takes almost 1-2 months to build up a NF cluster with less than 10 VM instances. When the scale of instances increases to over 50, the time extends to 3-4 months, or even more. One of our respondent said that they were still keeping on iterating and improving their testbed constantly. It is hard to imagine what a painful experience it is for newcomers who intend to participate into the NFV research community.

Therefore, we think that the time is ripe to consider a NFV benchmark suite that aims to greatly simplify the process of building a NFV testbed, especially for newcomers. To fulfill this goal, we need to address three questions:
\textit{1) which are the representative NFs and NFs chains?} For newcomers, it is frustrated to choose some representative NFs among NFs of various functions of various open source implementations. Besides, the order of NFs chained together is also important, and should be closed to the production environments as much as possible. Thus, the NFV benchmark should consist of a bunch of representative NFs and NFs chains widely accepted.
\textit{2) How to accelerate the buildup process?} The most disturbing part of buildup process is to install and configure all the NFs one by one, with endless package dependency and manual reading. We should leverage the benefit of virtualization which is ``build once, run everywhere''.
\textit{3) what metrics should we collect and present?} Researchers usually care about which metrics a testbed
can provide and how these metrics can be used to guide their research. This is a must-have feature we should take into account.

Considering these questions, we present \textbf{NFVInsight}, a suite of NF benchmarks that help users set up their own NFV testbeds easily and rapidly. NFVInsight has following characteristics:
% However, even though a suite of easy-to-use NFV benchmark is not yet existed. It is unavoidable to experience a time consuming process finding both open source software and proper chaining policies. According to our observation, most NFs used in papers are different open source implementations linked in different kinds of NF chain policies. So that, there is not yet a general baseline for measurement and comparison. Furthermore, the workload generator and network traffic trace used are also different, traces need to be provided to test different NF chains.



% We also did a survey among top conference researchers who have experiences setting up NFV environment. In our survey, we found that the deploying time varies much due to the scale. In average, it takes 1-2 months to build up a NF cluster having less than 10 VM instances. But when the scale of instances increase to over 50, the build up process can take 3-4 months or more. One of our respondent said that they were still keeping on iterating and improving their testbed constantly.



% In this paper, we develop a suite of NF benchmarks, which is supposed to have the following characteristics: 1) Representing typical NFs 2) Easy to use 3) Plenty metrics for measurement.

% According to our research and observation,
% the representative of an NFV benchmark
% should be satisfied in three aspects:
%\begin{itemize}
%\begin{enumerate}
%\item{\textbf{Representative NFs.}}
\textbf{1) Representative NFs \& NF chains.}
we referred to the NFV Introductory White Paper \cite{},
which defined ten scenarios of NFV use cases.
In the first version of our benchmark,
the open source implementation of NFs we collected
covers half of the ten use cases.
Table \ref{nfs} lists the basic information of NFs used in our benchmark.
%\item{\textbf{Representative NF chains.}}
% \textbf{2) Representative NF chains.}
For NF chains, we referred to ETSI standard documents of SFC
(Service Function Chaining) \cite{draft-ietf-sfc-dc-use-cases-06}
for the typical use case of service chains
in the scenarios of both enterprise user and datacenter.
%We also consulted our industrial partners for real world chaining policies.
The typical NF chains our benchmark provides are listed in Table \ref{chains}.
%\item{\textbf{Proper workload generator.}}
\textbf{2) Proper workload generator.}
Since each NF chain serves at different network level,
only one workload generator is not enough to test all the scenarios.
So we select different clients for each chain.
%and fixed the content of each chain.
%\end{itemize}
%\end{enumerate}
\textbf{3) Easy to use.}
The goal of the `easy to use' design is to
achieve one-week setting up as well as one-click test running,
no matter the scale of the testing environment.
To finish a test, users only need to touch one configuration file
and execute one single command.
In the end, the measurement report will be output to a file.
To implement our design,
we leverage Docker and Kubernets to pack NFs in dockers,
manage the images, and do launching automatically.
We use OVS to do switching and packet force forwarding.
Pre-defined scripts and Openflow rules are installed
to implement chaining and flow control.
%There are more complains pointing out their pain points: 1) Automate the setting up and testing process. 2) Configure and stabilize NFs (?). 3) Write rules to set up topology and enforce flow control.
%%our design to solve the pain points????
%`easy to use' design should solve pain points
\textbf{4) Metrics.}
In our benchmark, we first provide two most important metrics, i.e., latency and throughput.
NfvInsight measure latency in the granularity of per-packet and per-NF,
and output cumulative distribution of latency in the measurement report.

\textbf{Contributions.} We make the following contributions:
\begin{itemize}
\item
By surveying top conference authors, we disclose the truth that deploying an NFV environment is still a 
time-consuming and painful task;
\item
To the best of our knowledge, we present the first NFV benchmark suite to simplify the process of
setting up a NFV testbed;
\item
We conduct preliminary experiment to demonstrate that NfvInsight is able to be easily deployed and scale out
among multiple physical servers.
\end{itemize}

%The main contribution of our work is

%\section{Background and Motivation}
%
%\subsection{Network Function Virtualization}
%NFV involves multi-layers in the whole software stack,
%
%The concept of NFV chain
